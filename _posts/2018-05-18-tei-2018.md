---
layout: post
cover: assets/img/TEI_demo_header_2018.jpg
navigation: True
class: post-template
subclass: 'post'
tags: news
title:  "TEI '18: Prototype on E-textiles and Audio Commons"
author: Anna Xambó & Sophie Skach
---

The [Twelfth International Conference on Tangible, Embedded and Embodied Interactions](https://tei.acm.org/2018/) (TEI) was held last March 18--21 in Stockholm, Sweden. TEI is a fantastic conference that engages multidisciplinary researchers and practitioners in engineering, social sciences and the arts by means of tangible systems and experiences. This year there was a special presence of e-textiles in the form of workshops, talks and demos, following the year's theme of 'Post-Digital Design'.

We presented our Work-in-Progress paper _Embodied Interactions with E-Textiles and the Internet of Sounds for Performing Arts_ as a demo, a result of a collaboration between different projects at QMUL: e-textile research ([Sophie Skach](http://www.sophieskach.com/) and [Rebecca Stewart](http://theleadingzero.com/)), the Internet of Musical Things ([Luca Turchet](http://www.lucaturchet.it/) and [Mathieu Barthet](http://www.eecs.qmul.ac.uk/profiles/barthetmathieu.html)), and Audio Commons ([Mathieu Barthet](http://www.eecs.qmul.ac.uk/profiles/barthetmathieu.html), [Ariane Stolfi](http://www.ariane.stolfi.org/) and [Anna Xambó](http://annaxambo.me)).
For this showcase, we turned textiles into soft and wearable musical interfaces using the [Bela platform](https://bela.io/). Gestural movements or touch interactions allowed the wearer to explore the "Internet of Sounds" with different sonic features--ranging from drumming bellies to whistling sleeves.
A hoodie with snapped-on fabric sensors served as an interactive sound playground for its wearers. Stretch sensors on elbows and a pressure sensor on the hood each had a special audio effect assigned. So by moving, stretching, bending, and hitting, wearers could apply reverb, delay and a frequency shifter to modify the garment's sound base. The sound itself could be downloaded and even self composed through a specifically developed network app, that was linked with the micro controller deployed on the hoodie.


<a href="/assets/files/TEI_demo_2018.jpg" target="blank"><img style="margin:auto;margin-bottom:25px;margin-top:25px;max-width:800px;" class="img-responsive" src="/assets/files/TEI_demo_2018.jpg" alt="TEI 2018 demo">
</a>

We obtained positive and encouraging feedback from the visitors: _"Very cool! I love how natural it is to move and generate sound!"_ _"So much fun! I could really feel the performative potential when wearing it. Cool!"_ _"I like the design of the cloth. Would like to see real performance,"_ _"Let me see an actual performance with this! love it!,"_ _"Would love to have some more varied sounds -> to see or experience what matches to what! But fun project!,"_ _"Great experience! I'm not so much of an audio guy but this is great. I want this to be collaborative!"_

In a nutshell, visitors had fun and expect to see a follow up of the garments in a performance setting. It made a difference that they could wear it and experience it. However, we identified that the hoodie should add a bypass effect so that the original sound can be heard. Other improvements include the time of uploading the sounds from the Internet (now it could take up to a minute!).
The stretching sensors of the hoodie were dominating too much in the overall soundscape, which should be polished. The effects were centred in the high-frequencies, we aim to provide more dynamics in future iterations.

**Resources**:

* The paper is available [here](https://dl.acm.org/citation.cfm?doid=3173225.3173272): Sophie Skach, Anna Xambó, Luca Turchet, Ariane Stolfi, Rebecca Stewart, Mathieu Barthet (2018). [Embodied Interactions with E-Textiles and the Internet of Sounds for Performing Arts](https://dl.acm.org/citation.cfm?doid=3173225.3173272), published in Proceedings of the Twelfth International Conference on Tangible, Embedded, and Embodied Interaction.
* The source code to transfer sound files to the Bela platform can be found [here](https://github.com/AudioCommons/embedded-audiocommons).
